# Spec2RTL-Agent

**Automated Hardware Code Generation from Complex Specifications Using LLM Agent Systems**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![AutoGen 0.4](https://img.shields.io/badge/AutoGen-0.4-green.svg)](https://microsoft.github.io/autogen/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Implementation of the [Spec2RTL-Agent paper](https://arxiv.org/abs/2506.13905v2) - an LLM-based multi-agent system for end-to-end RTL generation from specification documents using AutoGen 0.4 framework.

---

## ğŸ¯ Project Overview
```
Specification PDF â†’ Understanding Module â†’ Coding Module â†’ Reflection Module â†’ RTL Code
                    (Summarize, Decompose)  (Progressive)   (Adaptive Debug)
```

### Key Features

- ğŸ¤– **Multi-Agent System**: AutoGen 0.4 async actor-based architecture
- ğŸ”„ **Multi-LLM Support**: OpenAI (GPT-4o, o1), Anthropic (Claude), Local models
- ğŸ“„ **Document Processing**: Multi-modal PDF extraction (text, tables, figures)
- ğŸ’° **Cost Tracking**: Built-in token usage and cost monitoring
- ğŸ³ **Dockerized**: Consistent development environment
- âœ… **Type-Safe**: Pydantic models throughout

---

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- OpenAI API key (for GPT-4o/o1)
- Optional: Anthropic API key (for Claude)

### Setup
```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/spec2rtl-agent.git
cd spec2rtl-agent

# Copy environment template
cp .env.example .env

# Add your API keys to .env
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...

# Build and start container
docker-compose build
docker-compose up -d

# Run hello world
docker-compose exec spec2rtl python main.py

# Run tests
docker-compose exec spec2rtl pytest tests/ -v
```

### Expected Output
```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Spec2RTL-Agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Hello World from Spec2RTL-Agent! ğŸš€                  â”‚
â”‚                                                      â”‚
â”‚ AutoGen 0.4 Multi-Agent System for RTL Generation    â”‚
â”‚ Ready to transform specifications into hardware code â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
âœ… System initialized successfully!
ğŸ“ Next: Implement Understanding Module
```

---

## ğŸ“ Project Structure
```
spec2rtl-agent/
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ llm_config.py          # LLM provider settings
â”‚   â””â”€â”€ agent_prompts.py       # Agent system prompts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                  # Core utilities
â”‚   â”‚   â”œâ”€â”€ llm/               # âœ… LLM provider abstraction
â”‚   â”‚   â”‚   â”œâ”€â”€ base_provider.py      # Abstract interface
â”‚   â”‚   â”‚   â”œâ”€â”€ openai_provider.py    # ğŸš§ OpenAI implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ anthropic_provider.py # â³ Anthropic (planned)
â”‚   â”‚   â”‚   â”œâ”€â”€ local_provider.py     # â³ Local models (planned)
â”‚   â”‚   â”‚   â””â”€â”€ provider_factory.py   # â³ Factory pattern
â”‚   â”‚   â”œâ”€â”€ document_loader.py # â³ PDF extraction
â”‚   â”‚   â””â”€â”€ data_models.py     # â³ Pydantic schemas
â”‚   â”œâ”€â”€ agents/                # Agent implementations
â”‚   â”‚   â”œâ”€â”€ understanding/     # ğŸš§ Phase 1 (Current)
â”‚   â”‚   â”‚   â”œâ”€â”€ summarization_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ decomposer_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ description_agent.py
â”‚   â”‚   â”‚   â””â”€â”€ verifier_agent.py
â”‚   â”‚   â”œâ”€â”€ coding/            # â³ Phase 2 (Planned)
â”‚   â”‚   â””â”€â”€ reflection/        # â³ Phase 3 (Planned)
â”‚   â””â”€â”€ orchestration/         # Agent coordination
â”‚       â””â”€â”€ understanding_pipeline.py
â”œâ”€â”€ data/                      # Input/Output data
â”‚   â”œâ”€â”€ input/specs/          # Specification PDFs
â”‚   â”œâ”€â”€ processed/sections/   # Extracted sections
â”‚   â””â”€â”€ output/summaries/     # Generated outputs
â”œâ”€â”€ tests/                    # âœ… Unit tests (5/5 passing)
â”œâ”€â”€ notebooks/                # Jupyter notebooks
â”œâ”€â”€ Dockerfile                # âœ… Docker setup
â”œâ”€â”€ docker-compose.yml        # âœ… Development environment
â””â”€â”€ main.py                   # âœ… Entry point
```

**Legend:** âœ… Complete | ğŸš§ In Progress | â³ Planned

---

## ğŸ“Š Implementation Progress

### Phase 1: Understanding & Reasoning Module (IN PROGRESS)

**Goal:** Transform unstructured spec PDFs into structured implementation plans

#### 1.1 Core Infrastructure âœ…

- [x] **LLM Provider Abstraction**
  - [x] Base provider interface with cost tracking
  - [x] Model capability detection (GPT-4 vs o1)
  - [x] Usage metrics and token counting
  - [x] Unit tests (5/5 passing)
- [ ] **OpenAI Provider** ğŸš§ (Next)
  - [ ] GPT-4o implementation
  - [ ] o1 reasoning model support
  - [ ] API key validation
  - [ ] Real API call testing
- [ ] **Data Models** â³
  - [ ] SpecSection schema
  - [ ] SectionSummary schema
  - [ ] ImplementationPlan schema
- [ ] **Document Loader** â³
  - [ ] PDF text extraction
  - [ ] Section boundary detection
  - [ ] Multi-modal content handling

#### 1.2 Agent Implementation â³

- [ ] Summarization Agent (First agent)
- [ ] Decomposer Agent
- [ ] Description Agent
- [ ] Verifier Agent
- [ ] Orchestration Pipeline

### Phase 2: Coding Module â³

- Progressive coding (Pseudocode â†’ Python â†’ C++)
- Prompt optimization
- Code verification

### Phase 3: Reflection Module â³

- Error analysis
- Adaptive debugging
- HLS integration

---

## ğŸ› ï¸ Development

### Running Tests
```bash
# Run all tests
docker-compose exec spec2rtl pytest tests/ -v

# Run specific test file
docker-compose exec spec2rtl pytest tests/test_base_provider.py -v

# Run with coverage
docker-compose exec spec2rtl pytest --cov=src tests/
```

### Code Quality
```bash
# Format code
docker-compose exec spec2rtl black src/ tests/

# Sort imports
docker-compose exec spec2rtl isort src/ tests/

# Lint
docker-compose exec spec2rtl flake8 src/ tests/

# Type check
docker-compose exec spec2rtl mypy src/
```

### Interactive Development
```bash
# Python REPL
docker-compose exec spec2rtl python

# IPython shell
docker-compose exec spec2rtl ipython

# Jupyter Lab
docker-compose exec spec2rtl jupyter lab --ip=0.0.0.0 --port=8888 --no-browser
# Then visit: http://localhost:8888
```

---

## ğŸ—ï¸ Architecture Highlights

### Multi-LLM Provider System
```python
from src.core.llm.base_provider import BaseLLMProvider
from src.core.llm.openai_provider import OpenAIProvider

# Create provider
provider = OpenAIProvider(
    model_name="gpt-4o",
    temperature=0.3,
    max_tokens=4096
)

# Get model client for AutoGen
model_client = provider.create_model_client()

# Track costs automatically
usage = provider.get_total_usage()
print(f"Total cost: ${usage.estimated_cost:.4f}")
```

### Cost Tracking

Every LLM call is automatically tracked:
- Input/output token counts
- Estimated costs (model-specific pricing)
- Cumulative usage per provider
- Per-request metrics

---

## ğŸ“š Documentation

- [AutoGen 0.4 Docs](https://microsoft.github.io/autogen/stable/)
- [Spec2RTL Paper](https://arxiv.org/abs/2506.13905v2)
- [AES Specification](./data/input/specs/AES_Spec.pdf)

---

## ğŸ¤ Contributing

1. Follow the existing code structure
2. Write tests for new features
3. Use type hints throughout
4. Run code quality tools before committing
5. Make atomic commits with clear messages

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file

---

## ğŸ™ Acknowledgments

Based on "Spec2RTL-Agent: Automated Hardware Code Generation from Complex Specifications Using LLM Agent Systems" by Yu et al. (Nvidia Research, Georgia Tech, Cadence)

---

## ğŸ“ Contact

For questions or issues, please open a GitHub issue.

---

**Status:** ğŸš§ Active Development | **Last Updated:** December 2024